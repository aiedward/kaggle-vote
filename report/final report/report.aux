\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\catcode 95\active
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Overall pipeline}\relax }}{2}{figure.caption.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Sorted feature importance scores} \textit  {Our goal was to capture the most important features and remove the less important ones to make the model's training process easier.}\relax }}{4}{figure.caption.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Most important features} \textit  {The relative importances shown here were derived from the ExtraTreesClassifier model, as described above.}\relax }}{5}{figure.caption.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Feature selection multiplier vs validation accuracy} \textit  {It is clear that this parameter must be carefully tweaked to achieve an optimal configuration. Note that the model here to evaluate the validation accuracy differed in parameters from the model we used for submissions. We had the best results with ~100 features remaining after feature selection, corresponding to a multiplier of roughly 1.7 in this figure.}\relax }}{5}{figure.caption.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Cross validation for single best model selection} \textit  {GBM attains the highest accuracy of $77.9\%$ followed by random forests(77.6), Adaboost(77.4), Extra Trees(77.2), Support Vector Machines (77.4), and Artificial Neural Networks (77.1).}\relax }}{6}{figure.caption.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Cross validation for model parameter selection} \textit  {Through an exhaustive grid search we determined the quadruple of parameters which gave the best validation accuracy around $78.2\%$. (a) Validation on min leaf size shows a peak at 15 (b) Validation on max depth shows peak at 3 (c) Validation on learning rate shows a peak at 0.1 (d) Validation on subsample shows a peak at 1}\relax }}{7}{figure.caption.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Cross validation accuracy vs prediction bias} \textit  {Validation accuracy is highest with a prediction bias of $0.013$. Qualitatively, a positive prediction bias means to predict in favor of class 2 (minority class). }\relax }}{8}{figure.caption.7}}
